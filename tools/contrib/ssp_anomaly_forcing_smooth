#! /usr/bin/env python3
"""

ssp_anomaly_forcing_smooth

Create anomaly forcing datasets for SSP scenarios that can be used by CESM datm model

load proper modules first, i.e.

../../py_env_create
conda activate ctsm_pylib

"""
import sys
import os
import subprocess
import datetime
import argparse
from getpass import getuser
import numpy as np
import netCDF4 as netcdf4


parser = argparse.ArgumentParser(description="Create anomaly forcing")
parser.add_argument(
    "sspnum",
    help="scenario number (1=SSP1-2.6, 2=SSP2-4.5, 3=SSP3-7.0, 4=SSP5-8.5)",
    nargs="?",
    type=int,
    default=0,
)
parser.add_argument(
    "--hist-or-ssp",
    help="save historical period (hist), ssp period (ssp; default), or both?",
    type=str,
    default="ssp",
    choices=["hist", "ssp", "both"],
)
parser.add_argument(
    "--output-dir",
    help="Top-level output directory (default: ./anomaly_forcing/). Sub-directory will be created for the selected scenario.",
    type=str,
    default=os.path.join(".", "anomaly_forcing"),
)
parser.add_argument(
    "--write_climo",
    help="write out climatology files and exit",
    action="store_true",
    default=False,
)
parser.add_argument(
    "--print_ssps",
    help="Just print out directory names and exit",
    action="store_true",
    default=False,
)

args = parser.parse_args()
if args.sspnum == 0:
    sys.exit("choose valid ssp number")

# -------------------------------------------------------

# Output file format
format = "NETCDF4_CLASSIC"

print("Create anomaly forcing data that can be used by CTSM in CESM")
# Input and output directories make sure they exist
datapath = "/glade/campaign/collections/cmip/CMIP6/timeseries-cmip6/"  # Path on casper

"""
The corrected SSP simulations:

    b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.101
    b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.102 (MOAR)
    b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.103

    b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.101
    b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.102 (MOAR)
    b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.103

    b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.101
    b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.102 (MOAR)
    b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.103

    b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.101
    b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.102 (MOAR)
    b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.103

historical runs used to initialize SSPs:
b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.001/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.010_v2.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.002/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.002-old/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.001/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.010_v2.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.002/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.003/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.004.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.003.oldTag/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.004.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP245.f09_g17.CMIP6-SSP2-4.5.001.BAD/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.010_v2.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.001/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.010_v2.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.002/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.003/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.004/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.005/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.006/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.001/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.010.clm2.r.2015-01-01-00000.nc'
b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.002/CaseDocs/lnd_in: finidat = \
              'b.e21.BHIST.f09_g17.CMIP6-historical.011.clm2.r.2015-01-01-00000.nc'

_v2 is just used for restart files that have been spatially interpolated

"""

spath = args.output_dir
if os.path.exists(datapath):
    print("Input data directory:" + datapath)
else:
    sys.exit("Could not find input directory: " + datapath)
if os.path.exists(spath):
    print("Output data directory:" + spath)
else:
    sys.exit("Could not find output directory: " + spath)

# Settings to run with
today = datetime.date.today()
creationdate = "_c" + today.strftime("%Y%m%d")
historydate = today.strftime("%a %b %d %Y")

sspdir_full = [
    "b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.101/",
    "b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.102/",
    "b.e21.BSSP126cmip6.f09_g17.CMIP6-SSP1-2.6.103/",
    "b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.101/",
    "b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.102/",
    "b.e21.BSSP245cmip6.f09_g17.CMIP6-SSP2-4.5.103/",
    "b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.101/",
    "b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.102/",
    "b.e21.BSSP370cmip6.f09_g17.CMIP6-SSP3-7.0.103/",
    "b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.101/",
    "b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.102/",
    "b.e21.BSSP585cmip6.f09_g17.CMIP6-SSP5-8.5.103/",
]

histdir_full = [
    "b.e21.BHIST.f09_g17.CMIP6-historical.010/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.011/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.004/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.010/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.011/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.004/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.010/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.011/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.004/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.010/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.011/",
    "b.e21.BHIST.f09_g17.CMIP6-historical.004/",
]

sim_pairs = zip(sspdir_full, histdir_full)
# print simulation pairs and exit
if args.print_ssps:
    print(datapath, "\n")
    for sim in sim_pairs:
        print("SSP: ", sim[0])
        print("historical: ", sim[1], "\n")
    sys.exit()

sspnum = args.sspnum

# hist_case needed?
hist_case = "b.e21.BHIST.f09_g17.CMIP6-historical.010"

if sspnum == 1:
    # SSP1-26
    ssptag = "SSP1-2.6"
    histdir = histdir_full[0:3]
    sspdir = sspdir_full[0:3]
elif sspnum == 2:
    # SSP2-45
    ssptag = "SSP2-4.5"
    histdir = histdir_full[3:6]
    sspdir = sspdir_full[3:6]
elif sspnum == 3:
    # SSP3-70
    ssptag = "SSP3-7.0"
    histdir = histdir_full[6:9]
    sspdir = sspdir_full[6:9]
elif sspnum == 4:
    # SSP5-85
    ssptag = "SSP5-8.5"
    histdir = histdir_full[9:12]
    sspdir = sspdir_full[9:12]
else:
    sys.exit("sspnum is out of range: " + sspnum)

num_ens = len(sspdir)
if num_ens != len(histdir):
    print("number of ensemble members not the same")
    sys.exit("number of members different")

# test w/ 1 ensemble member
num_ens = 3

# Setup output directory
sspoutdir = "CMIP6-" + ssptag
outdir = os.path.join(spath, sspoutdir)
if not os.path.exists(outdir):
    os.makedirs(outdir)

print("Output specific data directory :" + outdir)

# historical files are split by 50 year periods; use last period
hist_suffix = ["200001-201412.nc"]  # not standardized?!
# hist_suffix = ['-201412.nc']
# projections are split 2015/2064 2065/2100
ssp_suffix = ["201501-206412.nc", "206501-210012.nc"]
# ssp_suffix  = ['-206412.nc','-210012.nc']

climo_year = 2015
# ten years on either side (21 years total)
climo_base_nyrs = 21

write_climo = args.write_climo

nmo = 12

print("\n\n\n")

# needed to use QBOT and U10, not using V and U(for sfcwind)
field_in = ["TBOT", "RAIN", "FSDS", "FLDS", "QBOT", "PBOT", "WIND"]
field_out = ["tas", "pr", "rsds", "rlds", "huss", "ps", "sfcWind"]
units = ["K", "mm/s", "W m!U-2!N", "W m!U-2!N", "kg/kg", "Pa", "m/s"]
units_disp = ["K", "mm/s", "W m!U-2!N", "W m!U-2!N", "kg/kg", "Pa", "m/s"]
anomsf = [
    "anomaly",
    "scale factor",
    "scale factor",
    "scale factor",
    "anomaly",
    "anomaly",
    "anomaly",
]

field_out_wind = ["uas", "vas"]

nfields = len(field_in)

# --  Loop over forcing fields  ------------------------------------
for f in range(nfields):

    # --  Loop over ensemble members  ------------------------------
    for nens in range(num_ens):
        print("Beginning ensemble number ", nens + 1)

        hist_case = histdir[nens]
        dpath = datapath
        dfile = "/lnd/proc/tseries/month_1/"
        hdir = dpath + hist_case + dfile
        if args.hist_or_ssp != "hist":
            fut_case = sspdir[nens]
            fdir = dpath + fut_case + dfile

        # Check that directories exist
        if not os.path.exists(hdir):
            sys.exit("Could not find directory: " + hdir)
        if args.hist_or_ssp != "hist" and not os.path.exists(fdir):
            sys.exit("Could not find directory: " + fdir)

        # --  Get historical and SSP filenames  --------------------
        command = "ls " + hdir + "*." + field_in[f] + ".*.nc"
        x2 = subprocess.Popen(command, stdout=subprocess.PIPE, shell="True")
        x = x2.communicate()
        histfiles = x[0].decode("utf-8").split("\n")
        histfiles.remove("")

        if args.hist_or_ssp != "hist":
            command = "ls " + fdir + "*." + field_in[f] + ".*.nc"
            x2 = subprocess.Popen(command, stdout=subprocess.PIPE, shell="True")
            x = x2.communicate()
            sspfiles = x[0].decode("utf-8").split("\n")
            sspfiles.remove("")

        for hfile in histfiles:
            print(hfile.split("month_1/")[-1])
            if not os.path.exists(hfile):
                sys.exit(hfile + " does not exist")
        if args.hist_or_ssp != "hist":
            for sfile in sspfiles:
                print(sfile.split("month_1/")[-1])
                if not os.path.exists(sfile):
                    sys.exit(sfile + " does not exist")

        # --  Read in historical data  -----------
        f1 = netcdf4.MFDataset(histfiles, "r")
        if nens == 0:
            # read in coordinates
            lon = np.asfarray(f1.variables["lon"][:], np.float64)
            lat = np.asfarray(f1.variables["lat"][:], np.float64)
            hist_time = np.asfarray(f1.variables["time"][:], np.float64)
            hist_time_units = f1.variables["time"].units
            hist_time_longname = f1.variables["time"].long_name

            # read landfrac, landmask, and area
            landfrac = np.asfarray(f1.variables["landfrac"][:, :], np.float64)
            landmask = np.asfarray(f1.variables["landmask"][:, :], np.float64)
            area = np.asfarray(f1.variables["area"][:, :], np.float64)
            ind = np.where(landfrac > 1.0e10)
            landfrac[ind] = 0

            x = hist_time_units.split()[2]
            ref_year = float(x.split("-")[0])
            hist_yrstart = np.min(hist_time / 365.0 + ref_year).astype(int)
            if args.hist_or_ssp == "ssp":
                # overwrite hist_yrstart to select just 20 years prior to climo_year
                hist_yrstart = climo_year - (climo_base_nyrs - 1)
            hist_yrend = (np.max(hist_time / 365.0 + ref_year) - 1).astype(int)
            hist_nyrs = hist_yrend - hist_yrstart + 1
            if f == 0:
                print("hist years: ", hist_yrstart, hist_yrend, hist_nyrs)

            hist_ind = np.where(
                np.logical_and(
                    hist_time / 365.0 + ref_year > hist_yrstart,
                    hist_time / 365.0 + ref_year <= (hist_yrend + 1),
                )
            )[0]
            hist_time = hist_time[hist_ind]

            nlat = lat.size
            nlon = lon.size
            ntime = hist_time.size
            hist_fld = np.zeros((ntime, nlat, nlon))

        hist_fld += np.asfarray(f1.variables[field_in[f]][hist_ind, :, :], np.float64)
        f1.close()

        # add SNOW to RAIN
        if field_in[f] == "RAIN":
            histfiles2 = [file.replace("RAIN", "SNOW") for file in histfiles]
            f1 = netcdf4.MFDataset(histfiles2, "r")
            hist_fld += np.asfarray(f1.variables["SNOW"][hist_ind, :, :], np.float64)
            f1.close()

        if f == 0:
            print(
                "hist_time: ",
                hist_time[0] / 365.0 + ref_year,
                hist_time[-1] / 365.0 + ref_year,
            )

        # read in ssp data  ---------------------
        if args.hist_or_ssp != "hist":
            f1 = netcdf4.MFDataset(sspfiles, "r")
            if nens == 0:
                ssp_time = np.asfarray(f1.variables["time"][:], np.float64)
                ssp_time_units = f1.variables["time"].units
                ssp_time_longname = f1.variables["time"].long_name
                x = ssp_time_units.split()[2]
                ssp_ref_year = float(x.split("-")[0])

                # adjust ssp_time to reference time of hist_time
                # ssp_time += 365*(ssp_ref_year - ref_year)
                # ssp_ref_year = ref_year
                # adjust hist_time to reference time of ssp_time
                hist_time += 365 * (ref_year - ssp_ref_year)
                ref_year = ssp_ref_year

                # ssp_ind could be modified to subset data if needed...
                ssp_ind = np.arange(ssp_time.size, dtype=int)

                ssp_time = ssp_time[ssp_ind]
                long_name = f1.variables[field_in[f]].long_name
                ntime_ssp = ssp_time.size
                ssp_fld = np.zeros((ntime_ssp, nlat, nlon))

                ssp_yrstart = np.min(ssp_time / 365.0 + ref_year).astype(int)
                ssp_yrend = (np.max(ssp_time / 365.0 + ref_year) - 1).astype(int)
                ssp_nyrs = ssp_yrend - ssp_yrstart + 1

                if args.hist_or_ssp == "hist":
                    thisperiod_yrstart = hist_yrstart
                    thisperiod_yrend = hist_yrend
                elif args.hist_or_ssp == "ssp":
                    thisperiod_yrstart = ssp_yrstart
                    thisperiod_yrend = ssp_yrend
                elif args.hist_or_ssp == "both":
                    thisperiod_yrstart = hist_yrstart
                    thisperiod_yrend = ssp_yrend
                else:
                    raise RuntimeError(f"Handle --hist-or-ssp {args.hist_or_ssp}")
                thisperiod_nyrs = thisperiod_yrend - thisperiod_yrstart + 1

                if f == 0:
                    print(
                        f"{args.hist_or_ssp.upper()} years: ",
                        thisperiod_yrstart,
                        thisperiod_yrend,
                        thisperiod_nyrs,
                    )
                tot_nyrs = hist_nyrs + ssp_nyrs
                outfile_suffix = (
                    ".CESM."
                    + ssptag
                    + "."
                    + str(thisperiod_yrstart)
                    + "-"
                    + str(thisperiod_yrend)
                    + creationdate
                    + ".nc4"
                )

            ssp_fld += np.asfarray(f1.variables[field_in[f]][ssp_ind, :, :], np.float64)
            f1.close()

            # add SNOW to RAIN
            if field_in[f] == "RAIN":
                sspfiles2 = [file.replace("RAIN", "SNOW") for file in sspfiles]
                f1 = netcdf4.MFDataset(sspfiles2, "r")
                ssp_fld += np.asfarray(f1.variables["SNOW"][ssp_ind, :, :], np.float64)
                f1.close()

            if f == 0:
                print(
                    "ssp_time: ",
                    ssp_time[0] / 365.0 + ssp_ref_year,
                    ssp_time[-1] / 365.0 + ssp_ref_year,
                    ssp_time.size,
                )
    # --  end Loop over ensemble members  ------------------------------

    # normalize summed fields by number of ensemble members
    hist_fld = hist_fld / float(num_ens)
    if args.hist_or_ssp != "hist":
        ssp_fld = ssp_fld / float(num_ens)
        # concatenate arrays to form contiguous time series
        temp_fld = np.concatenate((hist_fld, ssp_fld), axis=0)
        full_time = np.concatenate((hist_time, ssp_time), axis=0)
    else:
        temp_fld = hist_fld
        full_time = hist_time
    tm = full_time.size

    # smooth data by applying boxcar averaging to sequence of months
    stemp_fld = np.copy(temp_fld)
    for n in range(tm):
        # 21 years of jan, feb, etc. centered on each month in data
        ind = nmo * (np.arange(climo_base_nyrs) - (climo_base_nyrs - 1) / 2) + n
        # account for edges
        m = np.where(np.logical_and(ind >= 0, ind < tm))[0]
        ind2 = ind[m].astype(int)

        stemp_fld[n, :, :] = np.sum(temp_fld[ind2, :, :], axis=0) / float(ind2.size)

    if f == 0:
        print(
            "full time: ",
            full_time[0] / 365.0 + ref_year,
            full_time[-1] / 365.0 + ref_year,
            full_time.size,
        )

    # create climatology of smoothed data
    climo = np.zeros((nmo, nlat, nlon))
    t_climo_year = np.argmin(np.abs((full_time / 365.0 + ref_year) - climo_year))
    # shift to january of climo_year
    t_climo_year += 1
    if f == 0:
        print((full_time[t_climo_year] / 365.0 + ref_year))
    for n in range(nmo):
        ind = (
            nmo * (np.arange(climo_base_nyrs) - (climo_base_nyrs - 1) / 2) + t_climo_year + n
        ).astype(int)
        climo[n, :, :] = np.sum(stemp_fld[ind, :, :], axis=0) / float(ind.size)

    if f == 0:
        print("climo calculated")

    # extract smoothed data for period of interest
    def get_year_from_time(time, t, ref_year):
        return time[t] / 365.0 + ref_year

    if args.hist_or_ssp == "hist":
        t_hist_end = len(full_time) - 1
        if f == 0:
            print(
                f"{get_year_from_time(full_time, 0, ref_year)}-{get_year_from_time(full_time, t_hist_end, ref_year)}"
            )
        fld_smoothed = stemp_fld
        nyrs = hist_nyrs
        thisperiod_time = hist_time
        thisperiod_time_units = hist_time_units
        thisperiod_time_longname = hist_time_longname
        thisperiod_yrstart = hist_yrstart
        thisperiod_yrend = hist_yrend
    elif args.hist_or_ssp == "ssp":
        t_ssp_start = (ssp_yrstart - hist_yrstart) * nmo
        if f == 0:
            print(
                f"{get_year_from_time(full_time, t_ssp_start, ref_year)}-{get_year_from_time(full_time, len(full_time)-1, ref_year)}"
            )
        fld_smoothed = stemp_fld[t_ssp_start:, :, :]
        nyrs = ssp_nyrs
        thisperiod_time = ssp_time
        thisperiod_time_units = ssp_time_units
        thisperiod_time_longname = ssp_time_longname
        thisperiod_yrstart = ssp_yrstart
        thisperiod_yrend = ssp_yrend
    elif args.hist_or_ssp == "both":
        if f == 0:
            print(
                f"{get_year_from_time(full_time, 0, ref_year)}-{get_year_from_time(full_time, len(full_time)-1, ref_year)}"
            )
        fld_smoothed = stemp_fld
        nyrs = hist_nyrs + ssp_nyrs
        thisperiod_time = full_time
        thisperiod_time_units = hist_time_units
        thisperiod_time_longname = hist_time_longname
        thisperiod_yrstart = hist_yrstart
        thisperiod_yrend = ssp_yrend
    else:
        raise RuntimeError(f"Handle --hist-or-ssp {args.hist_or_ssp}")

    # calculate anomaly relative to climatology
    anom_fld = np.zeros((fld_smoothed.shape))
    for y in range(nyrs):
        ind = (np.arange(nmo) + y * nmo).astype(int)
        if anomsf[f] == "anomaly":
            anom_fld[ind, :, :] = fld_smoothed[ind, :, :] - climo

        if anomsf[f] == "scale factor":
            tmp = fld_smoothed[ind, :, :]
            ind2 = np.where(climo != 0.0)
            # initialize scalar anomaly to 1
            tmp2 = np.ones(tmp.shape)
            # calculate scalar anomaly
            tmp2[ind2] = tmp[ind2] / climo[ind2]

            # place upper limit on scalar anomalies
            max_scale_factor = 5.0
            if field_in[f] == "FSDS":
                max_scale_factor = 2.0
            ind2 = np.where(tmp2 > max_scale_factor)
            tmp2[ind2] = max_scale_factor
            anom_fld[ind, :, :] = tmp2
    # ----- end of year loop -------

    # write out climo to check field  -------------------------
    if write_climo:
        # Use NetCDF4 format, because using older NetCDF formats are too slow
        w = netcdf4.Dataset(
            outdir + field_out[f] + "_climo" + creationdate + ".nc", "w", format=format
        )
        w.createDimension("lat", int(nlat))
        w.createDimension("lon", int(nlon))
        w.createDimension("time", int(nmo))

        wtime = w.createVariable("time", np.float64, ("time",))
        wlat = w.createVariable("lat", np.float64, ("lat",))
        wlon = w.createVariable("lon", np.float64, ("lon",))
        wvar = w.createVariable(
            field_out[f],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )
        wtime[
            :,
        ] = full_time[0:12]
        wlon[
            :,
        ] = lon
        wlat[
            :,
        ] = lat
        wvar[:, :, :] = climo
        w.close()

        # Use NetCDF4 format, because using older NetCDF formats are too slow
        w_filename = outdir + field_out[f] + "_smooth" + creationdate + ".nc4"
        w = netcdf4.Dataset(w_filename, "w", format=format)
        w.createDimension("lat", int(nlat))
        w.createDimension("lon", int(nlon))
        w.createDimension("time", int(tm))

        wtime = w.createVariable("time", np.float64, ("time",))
        wlat = w.createVariable("lat", np.float64, ("lat",))
        wlon = w.createVariable("lon", np.float64, ("lon",))
        wvar = w.createVariable(
            field_out[f],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )
        wvar2 = w.createVariable(
            "smooth_" + field_out[f],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )

        wtime[:] = full_time
        wlon[
            :,
        ] = lon
        wlat[
            :,
        ] = lat
        wvar[:, :, :] = temp_fld
        wvar2[:, :, :] = stemp_fld
        w.close()
        w_filename_cdf5 = w_filename.replace(".nc4", ".nc")
        subprocess.Popen(
            f"nccopy -k 'cdf5' {w_filename} {w_filename_cdf5} && rm {w_filename}",
            stdout=subprocess.PIPE,
            shell="True",
        )
        print("Exit early after writing out climatology\n\n")
        sys.exit()

    # create netcdf file  ---------------------------------

    if f == 0:
        # Use NetCDF4 format, because using older NetCDF formats are too slow
        # Will need to convert to CDF5 format at the end, as we can't seem to
        # output in CDF5 format using netCDF4 python interfaces
        outfilename = outdir + "/" + "af.allvars" + outfile_suffix
        print("Creating: " + outfilename)
        outfile = netcdf4.Dataset(outfilename, "w", format=format)

        # creation date on the file
        command = 'date "+%Y/%m/%d"'
        x2 = subprocess.Popen(command, stdout=subprocess.PIPE, shell="True")
        x = x2.communicate()
        timetag = x[0].decode("utf-8").strip()

        outfile.Created_on = timetag

        outfile.title = "anomaly forcing data"
        outfile.note1 = (
            "Anomaly/scale factors calculated relative to "
            + str(climo_year - (climo_base_nyrs - 1) / 2)
            + "-"
            + str(climo_year + (climo_base_nyrs - 1) / 2)
        )
        outfile.history = historydate + ": created by " + sys.argv[0]
        stdout = os.popen("git describe")
        outfile.gitdescribe = stdout.read().rstrip()
        outfile.Source = "CMIP6 CESM simulations"
        outfile.Conventions = "CF-1.0"
        outfile.comment = (
            "Monthly scale factors for given SSP scenario compared to a climatology based on"
            + " data centered on "
            + str(climo_year)
            + " over the range given in note1"
        )
        outfile.number_of_ensemble_members = str(num_ens)
        outfile.Created_by = getuser()

        for nens in range(num_ens):
            hdir = dpath + histdir[nens] + dfile
            if nens == 0:
                outfile.Created_from_historical_dirs = hdir
            else:
                outfile.Created_from_historical_dirs += ", " + hdir
            if args.hist_or_ssp != "hist":
                fdir = dpath + sspdir[nens] + dfile
                if nens == 0:
                    outfile.Created_from_scenario_dirs = fdir
                else:
                    outfile.Created_from_scenario_dirs += ", " + fdir

        outfile.History_years = str(hist_yrstart) + "," + str(hist_yrend)
        if args.hist_or_ssp != "hist":
            outfile.Scenario_years = str(ssp_yrstart) + "," + str(ssp_yrend)
        outfile.institution = "National Center for Atmospheric Research"

        outfile.createDimension("lat", size=int(nlat))
        outfile.createDimension("lon", size=int(nlon))
        outfile.createDimension("time", None)

        wtime = outfile.createVariable("time", np.float64, ("time",))
        wlat = outfile.createVariable("lat", np.float64, ("lat",))
        wlon = outfile.createVariable("lon", np.float64, ("lon",))
        wmask = outfile.createVariable("landmask", np.int32, ("lat", "lon"))
        warea = outfile.createVariable("area", np.float64, ("lat", "lon"))
        wfrac = outfile.createVariable("landfrac", np.float64, ("lat", "lon"))
        wtime.units = thisperiod_time_units
        wlon.units = "degrees_east"
        wlat.units = "degrees_north"
        warea.units = "km2"
        wfrac.units = "unitless"
        wmask.units = "unitless"

        # wtime.long_name = 'Months since January '+str(fut_yrstart)
        wtime.long_name = thisperiod_time_longname
        wlon.long_name = "Longitude"
        wlat.long_name = "Latitude"
        warea.long_name = "Grid cell area"
        wfrac.long_name = "Grid cell land fraction"
        wmask.long_name = "Grid cell land mask"
        wlon.mode = "time-invariant"
        wlat.mode = "time-invariant"
        warea.mode = "time-invariant"
        wfrac.mode = "time-invariant"
        wmask.mode = "time-invariant"

        wtime.calendar = "noleap"

        # write to file  --------------------------------------------
        # wtime_offset = 0
        # adjust time to middle of month
        # wtime_offset = -15
        wtime_offset = 15 - thisperiod_time[0]
        wtime[:] = thisperiod_time + wtime_offset
        wtime.calendar = "noleap"
        wlon[:] = lon
        wlat[:] = lat
        wmask[:, :] = landmask
        wfrac[:, :] = landfrac
        warea[:, :] = area
    # -- End if on open file

    if field_out[f] == "sfcWind":
        wvar = outfile.createVariable(
            field_out_wind[0],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )
    else:
        wvar = outfile.createVariable(
            field_out[f],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )
    wvar.units = units[f]
    wvar.mode = "time-dependent"

    # write to file  --------------------------------------------
    if field_out[f] == "sfcWind":
        wvar.long_name = str(long_name) + " U component " + anomsf[f]
    else:
        wvar.long_name = str(long_name) + " " + anomsf[f]

    if field_out[f] == "sfcWind":
        wvar[:, :, :] = anom_fld / np.sqrt(2)
    else:
        wvar[:, :, :] = anom_fld

    # List of source files
    wvar.historical_source_files = "".join(histfiles).replace(hdir, "")
    wvar.scenario_source_files = "".join(sspfiles).replace(fdir, "")

    # create second wind field for V component
    if field_out[f] == "sfcWind":
        command = 'date "+%y%m%d"'
        x2 = subprocess.Popen(command, stdout=subprocess.PIPE, shell="True")
        x = x2.communicate()
        timetag = x[0].decode("utf-8").strip()

        wvar = outfile.createVariable(
            field_out_wind[1],
            np.float64,
            ("time", "lat", "lon"),
            fill_value=np.float64(1.0e36),
        )
        wvar.units = units[f]
        wvar.cell_methods = "time: mean"
        wvar.long_name = str(long_name) + " V component " + anomsf[f]

        # write to file  --------------------------------------------
        wvar[:, :, :] = anom_fld / np.sqrt(2)

        # List of source files
        wvar.historical_source_files = "".join(histfiles).replace(hdir, "")
        wvar.scenario_source_files = "".join(sspfiles).replace(fdir, "")

    # -- end if statement for write for V field --------

# --  End Loop over forcing fields  ------------------------------------
outfile.close()

# Convert to CDF5
outfilename_cdf5 = outfilename.replace(".nc4", ".nc")
subprocess.Popen(
    f"nccopy -k 'cdf5' {outfilename} {outfilename_cdf5} && rm {outfilename}",
    stdout=subprocess.PIPE,
    shell="True",
)

print("\n\nSuccessfully made anomaly forcing datasets\n")
